Upon completion of all course modules, you should be able to:

**1. Module 1: Introduction to Data and the Normal Distribution**

  1. Identify variables as numerical and categorical and further classify based on the nature of the 
  2. Define associated variables as variables that show some relationship with one another. Further categorize this relationship as positive or negative association, when possible.
  <!-- 3. Identify the explanatory variable in a pair of variables as the variable suspected of affecting the other. However, note that labeling variables as explanatory and response does not guarantee that the relationship between the two is actually causal, even if there is an association identified between the two variables. -->
  4. When describing the distribution of a numerical variable, mention its shape, center, and spread, as well as any unusual observations.
  5. Identify the shape of a distribution as symmetric, right skewed, or left skewed, and unimodal, bimodal, multimodal, or uniform.

\vspace{.25cm}

**2. Module 2: Foundations for Statistical Inference with Numerical and Categorical Data**

  1. Define the standardized (Z) score of a data point as the number of standard deviations it is away from the mean:
  $$Z = \frac{x-\mu}{\sigma}$$
  2. Use the $Z$-score to determine the corresponding percentile score of a data point as well as to assess whether or not a particular observation is considered to be statistically unusual ($\pm$ 2 standard deviations away from the mean)
  3. Assess whether or not a distribution is nearly normal using the 68-95-99.7% rule or graphical methods such as a normal probability plot.
  4. Define sample statistic as a point estimate for a population parameter, for example, the sample proportion is used to estimate the population proportion, and note that point estimate and sample statistic are synonymous.
  5. Recognize that point estimates (such as the sample proportion) will vary from one sample to another, and define this variability as sampling variation.
  
<!-- \vspace{.25cm} -->

<!-- **3. Module 3: Statistical Inference for Numerical and Categorical Data** -->

<!--   1. Define population proportion $p$ (parameter) and sample proportion $\hat{p}$ (point estimate). -->
<!--   2. Calculate the sampling variability of the proportion, the standard error, as: -->
<!-- $$ SE= \sqrt{\frac{p(1-p)}{n}}, $$ where $p$ is the population proportion. -->
<!--   - Note that when the population proprtion, $p$, is not known (amlost always), this can be estimated using the sample proportion, $SE = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$. -->

<!--   3. Use the $t$-distribution for inference on a single mean, difference of paired (dependent) means, and difference of independent means. -->
<!--   4. Explain why the $t$-distribution helps make up for the additional variability introduced by using s (sample standard deviation) in calculation of the standard error, in place of $\sigma$ (population standard deviation). -->
<!--   5. Use a $t$-statistic, with degrees of freedom $df$ = $n$ âˆ’ 1 for inference for a population mean -->

<!-- \vspace{.25cm} -->

<!-- **4. Module 4: Simple and Multiple Regression** -->

<!--   1. Define the explanatory variable as the independent variable (predictor), and the response variable as the dependent variable (predicted). -->
<!--   2. Produce scatterplots of response variables ($y$) against explanatory variables ($x$). -->
<!--   3. Fit a simple linear regresion model using statistical software. -->
<!--   4. When describing the association between two numerical variables, evaluate direction and strength. -->